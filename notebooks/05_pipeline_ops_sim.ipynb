{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9ecc91d0-9d65-4964-84e4-7de40bdadb71",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Databricks notebook source\n",
    "# ------------------------------------------------------------------------------\n",
    "# Notebook: 05_pipeline_ops_sim\n",
    "# Purpose : Simulate productionizing the medallion pipeline by orchestrating\n",
    "#           other notebooks with dbutils.notebook.run and basic logging.\n",
    "#\n",
    "# Exam Coverage (Databricks Certified Data Engineer Associate – Exam Guide 2025-07-30)\n",
    "# - Section 4: Productionizing Data Pipelines\n",
    "#   - Databricks Workflows and Lakeflow Jobs concepts.\n",
    "#   - Job deployment, retries and repair/rerun patterns (conceptual).\n",
    "#   - Using serverless compute for auto-optimized jobs (conceptual).\n",
    "# - Section 1: Databricks Intelligence Platform\n",
    "#   - Understanding job behavior and compute choices at a high level.\n",
    "#\n",
    "# Key Practices\n",
    "# - Use dbutils.notebook.run to orchestrate steps with shared parameters.\n",
    "# - Implement fail-fast behavior when a step returns a non-OK status.\n",
    "# - Log start and end timestamps for basic observability.\n",
    "# ------------------------------------------------------------------------------\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a4aca244-f8fa-48d4-b2ae-07a14f17bef9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Exam Focus – Productionizing Pipelines (Section 4)\n",
    "\n",
    "This notebook simulates how medallion pipelines are productionized:\n",
    "\n",
    "- Orchestrating multiple notebooks with `dbutils.notebook.run`.\n",
    "- Passing parameters such as `catalog`, `schema`, and `volume`.\n",
    "- Implementing fail-fast behavior when a task fails.\n",
    "- Mapping this pattern to Databricks **Workflows** and **Lakeflow Jobs**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "539a1986-7c7b-4d5f-9838-90386692307e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Chicago Taxi – Pipeline Orchestration (DBCE)\n",
    "\n",
    "Purpose: Simulate production-style orchestration by chaining notebooks with parameters, minimal logging, and status propagation.\n",
    "\n",
    "Exam coverage:\n",
    "- Productionizing pipelines (Jobs/Workflows concepts via `dbutils.notebook.run`).\n",
    "- Notebook capabilities (widgets, parameter passing).\n",
    "- Fail-fast and simple run logs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "71c0167a-b511-4adc-8995-c94096d240ab",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Orchestration imports and small helpers\n",
    "from datetime import datetime, UTC\n",
    "import posixpath\n",
    "\n",
    "# Simple log printer (kept minimal for CE)\n",
    "def log_event(event: str) -> None:\n",
    "    print(f\"[{datetime.now(UTC).isoformat(timespec='seconds')}] {event}\")\n",
    "\n",
    "#Resolve sibling notebook path robustly\n",
    "def sibling_notebook(current_path: str, target_name: str) -> str:\n",
    "    return posixpath.join(posixpath.dirname(current_path), target_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a13872d2-d99e-4ea4-be13-66d9b1c2c55b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Pipeline parameters and base paths\n",
    "dbutils.widgets.text(\"catalog\", \"taxi_catalog\")\n",
    "dbutils.widgets.text(\"schema\", \"taxi_schema\")\n",
    "dbutils.widgets.text(\"volume\", \"taxi_volume\")\n",
    "\n",
    "catalog_name = dbutils.widgets.get(\"catalog\")\n",
    "schema_name  = dbutils.widgets.get(\"schema\")\n",
    "volume_name  = dbutils.widgets.get(\"volume\")\n",
    "\n",
    "base_path  = f\"/Volumes/{catalog_name}/{schema_name}/{volume_name}\"\n",
    "bronze_path = f\"{base_path}/bronze\"\n",
    "silver_path = f\"{base_path}/silver\"\n",
    "gold_path   = f\"{base_path}/gold\"\n",
    "\n",
    "# Common args to pass downstream\n",
    "run_args = {\"catalog\": catalog_name, \"schema\": schema_name, \"volume\": volume_name}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1c8637e3-d277-4731-9468-1e31155d115a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "catalog = dbutils.widgets.get(\"catalog\")\n",
    "schema = dbutils.widgets.get(\"schema\")\n",
    "volume = dbutils.widgets.get(\"volume\")\n",
    "\n",
    "def run_step(notebook_path: str, step_name: str) -> None:\n",
    "    print(f\"[{datetime.utcnow().isoformat()}] Starting step: {step_name}\")\n",
    "    result = dbutils.notebook.run(\n",
    "        notebook_path,\n",
    "        timeout_seconds=0,\n",
    "        arguments={\n",
    "            \"catalog\": catalog,\n",
    "            \"schema\": schema,\n",
    "            \"volume\": volume,\n",
    "        },\n",
    "    )\n",
    "    if result != \"OK\":\n",
    "        raise RuntimeError(f\"Step {step_name} failed with result: {result}\")\n",
    "    print(f\"[{datetime.utcnow().isoformat()}] Finished step: {step_name}\")\n",
    "\n",
    "# Orchestration (00 is usually manual; start from 01)\n",
    "run_step(\"/Workspace/01_bronze_ingestion_autoloader\", \"bronze_ingestion\")\n",
    "run_step(\"/Workspace/02_silver_transformations\", \"silver_transformations\")\n",
    "run_step(\"/Workspace/03_gold_analytics\", \"gold_analytics\")\n",
    "run_step(\"/Workspace/04_quality_governance\", \"quality_governance\")\n",
    "\n",
    "dbutils.notebook.exit(\"OK\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "92afcddd-3c92-4c60-b237-f49092526d10",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Workflows and Lakeflow (exam notes)\n",
    "\n",
    "- Databricks Workflows:\n",
    "  - Native orchestrator for data and AI pipelines.\n",
    "  - Jobs with one or more tasks (notebooks, SQL, Python scripts, DLT).\n",
    "  - Supports schedules, retries, alerts and different cluster types, including serverless.\n",
    "- Lakeflow Jobs:\n",
    "  - Higher-level orchestration for data pipelines across ingestion, transformation and delivery.\n",
    "  - Deep integration with Unity Catalog and Delta Live Tables.\n",
    "- Community Edition:\n",
    "  - Does not expose full Workflows / Lakeflow features.\n",
    "  - Concepts still apply and are tested in the exam; this notebook simulates them using `dbutils.notebook.run`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4a5ee109-2cf9-4175-8be4-ecb57ecebfdc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Chain notebooks with parameters, minimal logging, and fail-fast behavior\n",
    "\n",
    "# Resolve current notebook path once\n",
    "ctx = dbutils.notebook.entry_point.getDbutils().notebook().getContext()\n",
    "current_path = str(ctx.notebookPath().get())  # ensure plain str\n",
    "\n",
    "steps = [\n",
    "    \"00_setup_project\",\n",
    "    \"01_bronze_ingestion_autoloader\",\n",
    "    \"02_silver_transformations\",\n",
    "    \"03_gold_analytics\",\n",
    "    \"04_quality_governance\",\n",
    "]\n",
    "\n",
    "for step in steps:\n",
    "    target = sibling_notebook(current_path, step)\n",
    "    log_event(f\"RUN -> {target} with args {run_args}\")\n",
    "    try:\n",
    "        res = dbutils.notebook.run(target, 0, arguments=run_args)\n",
    "        log_event(f\"OK <- {step}: {res}\")\n",
    "\n",
    "        # Normalize return and validate\n",
    "        res_norm = \"OK\" if res is None else str(res).strip().upper()\n",
    "        if res_norm not in {\"OK\", \"SUCCESS\"}:\n",
    "            raise RuntimeError(f\"Unexpected return from {step}: {res}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        log_event(f\"FAIL <- {step}: {e}\")\n",
    "        dbutils.notebook.exit(f\"FAILED at {step}: {e}\")\n",
    "# End-to-end sanity\n",
    "_ = spark.table(f\"{catalog_name}.{schema_name}.chicago_taxi_gold_v\").limit(1).count()\n",
    "log_event(\"Sanity gold view ok\")\n",
    "\n",
    "dbutils.notebook.exit(\"OK\")  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d0046481-aba3-40c2-a340-a1b6cfc4b4f2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "05_pipeline_ops_sim",
   "widgets": {
    "catalog": {
     "currentValue": "taxi_catalog",
     "nuid": "898751bb-79c7-472b-9075-d1184a1b96dc",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "taxi_catalog",
      "label": null,
      "name": "catalog",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "taxi_catalog",
      "label": null,
      "name": "catalog",
      "options": {
       "widgetType": "text",
       "autoCreated": false,
       "validationRegex": null
      }
     }
    },
    "schema": {
     "currentValue": "taxi_schema",
     "nuid": "02f5596c-59aa-4a76-9cd7-13da735ba89b",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "taxi_schema",
      "label": null,
      "name": "schema",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "taxi_schema",
      "label": null,
      "name": "schema",
      "options": {
       "widgetType": "text",
       "autoCreated": false,
       "validationRegex": null
      }
     }
    },
    "volume": {
     "currentValue": "taxi_volume",
     "nuid": "237b610a-7529-4142-b532-e93791a5fd7c",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "taxi_volume",
      "label": null,
      "name": "volume",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "taxi_volume",
      "label": null,
      "name": "volume",
      "options": {
       "widgetType": "text",
       "autoCreated": false,
       "validationRegex": null
      }
     }
    }
   }
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
